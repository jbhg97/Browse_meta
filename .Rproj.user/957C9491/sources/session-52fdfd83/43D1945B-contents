---
title: "R code for Eigenvector-based spatial modelling of [Browsing damage]"
author: "Mara & Tobias - edited James Grimsdale"
date: "2020-02-21 - edited 2023-09-25"
output: html_document
---

```{r}
knitr::opts_chunk$set(echo = TRUE)
```

### This document contains the key source code for the statistical analyses, supplementary tables, and figures that refer to the eigen-vector based spatial modelling of the variation in browsing damage.

### The first section uses Distance-based Moran Eigenvector Maps (dbMEMs) and Redundancy Analyses (RDA) to quantify spatial variation in browsing damage across the surveyed coupes, and test if this variation can be explained by variation in predictors.

### The second section makes use of an analogous approach within a random effects regression framework to analyse greenness and blackness separately. This approach also makes it possible to test if the impact of each climatic predictor on the colour trait (greenness OR blackness) varies across the landscape.

```{r include=FALSE}

# We will need these packages
library(pacman)

p_load(tidyverse, corrgram, sp, adespatial, openxlsx, tibble, LandGenCourse, readxl, spdep, mapview, gridExtra, tibble, proxy, FactoMineR, ggpubr, corrplot, geosphere, vegan, ade4, grid, here , lattice, nlme, MuMIn, ggplot2, spmoran, sf, leafem)
```

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}

# There are some functions needed to run this code
# Plot obtained from: GitHub- JoeyBernhardt/NumericalEcology/sr.value.R

sr.value <- function (dfxy, z, xax = 1, yax = 2, method = c("bubble",
                                                            "greylevel"), zmax = NULL, csize = 1, cpoint = 0, pch = 20,
                      clegend = 0.75, neig = NULL, cneig = 1, xlim = NULL, ylim = NULL,
                      grid = TRUE, addaxes = TRUE, cgrid = 0.75, include.origin = TRUE,
                      origin = c(0, 0), sub = "", csub = 1, possub = "topleft",
                      pixmap = NULL, contour = NULL, area = NULL, add.plot = FALSE)
  #
  # Slightly modified version of ade4's s.value() graphical function.
  # Draws round instead of square bubbles in some plots when argument 
  # "bubble" is called.
  #
  # License: GPL-2
  # Author of the original function s.value: Daniel Chessel
  # Modification: Francois Gillet, 25 August 2012
  #
{
  dfxy <- data.frame(dfxy)
  if (length(z) != nrow(dfxy))
    stop(paste("Non equal row numbers", nrow(dfxy), length(z)))
  opar <- par(mar = par("mar"))
  on.exit(par(opar))
  par(mar = c(0.1, 0.1, 0.1, 0.1))
  coo <- scatterutil.base(dfxy = dfxy, xax = xax, yax = yax,
                          xlim = xlim, ylim = ylim, grid = grid, addaxes = addaxes,
                          cgrid = cgrid, include.origin = include.origin, origin = origin,
                          sub = sub, csub = csub, possub = possub, pixmap = pixmap,
                          contour = contour, area = area, add.plot = add.plot)
  if (!is.null(neig))
  {
    if (is.null(class(neig))) neig <- NULL
    if (class(neig) != "neig") neig <- NULL
    deg <- attr(neig, "degrees")
    if (length(deg) != length(coo$x)) neig <- NULL
  }
  if (!is.null(neig))
  {
    fun <- function(x, coo)
    {
      segments(coo$x[x[1]], coo$y[x[1]], coo$x[x[2]], coo$y[x[2]],
               lwd = par("lwd") * cneig)
    }
    apply(unclass(neig), 1, fun, coo = coo)
  }
  method <- method[1]
  if (method == "greylevel")
  {
    br0 <- pretty(z, 6)
    nborn <- length(br0)
    coeff <- diff(par("usr")[1:2])/15
    numclass <- cut.default(z, br0, include = TRUE, lab = FALSE)
    valgris <- seq(1, 0, le = (nborn - 1))
    h <- csize * coeff
    for (i in 1:(nrow(dfxy)))
    {
      symbols(coo$x[i], coo$y[i], circles = h/2, 
              bg = gray(valgris[numclass[i]]),
              add = TRUE, inch = FALSE)
    }
    scatterutil.legend.circle.grey(br0, valgris, h/2, clegend)
    if (cpoint > 0) points(coo$x, coo$y, pch = pch, cex = par("cex") * cpoint)
  }
  else if (method == "bubble")
  {
    coeff <- diff(par("usr")[1:2])/15
    sq <- sqrt(abs(z))
    if (is.null(zmax)) zmax <- max(abs(z))
    w1 <- sqrt(zmax)
    sq <- csize * coeff * sq/w1
    for (i in 1:(nrow(dfxy)))
    {
      if (sign(z[i]) >= 0)
      {
        symbols(coo$x[i], coo$y[i], circles = sq[i]/2, bg = "black", 
                fg = "white", add = TRUE, inch = FALSE)
      }
      else
      {
        symbols(coo$x[i], coo$y[i], circles = sq[i]/2, bg = "white", 
                fg = "black", add = TRUE, inch = FALSE)
      }
    }
    br0 <- pretty(z, 4)
    l0 <- length(br0)
    br0 <- (br0[1:(l0 - 1)] + br0[2:l0])/2
    sq0 <- sqrt(abs(br0))
    sq0 <- csize * coeff * sq0/w1
    sig0 <- sign(br0)
    if (clegend > 0) scatterutil.legend.bw.circle(br0, sq0, sig0, clegend)
    if (cpoint > 0) points(coo$x, coo$y, pch = pch, cex = par("cex") * cpoint)
  }
  else if (method == "circlesize") print("not yet implemented")
  if (!add.plot) box()
  invisible(match.call())
}



scatterutil.legend.bw.circle <- function (br0, sq0, sig0, clegend)
{
  br0 <- round(br0, dig = 6)
  cha <- as.character(br0[1])
  for (i in (2:(length(br0)))) cha <- paste(cha, br0[i], sep = " ")
  cex0 <- par("cex") * clegend
  yh <- max(c(strheight(cha, cex = cex0), sq0))
  h <- strheight(cha, cex = cex0)
  y0 <- par("usr")[3] + yh/2 + h/2
  ltot <- strwidth(cha, cex = cex0) + sum(sq0) + h
  rect(par("usr")[1] + h/4, y0 - yh/2 - h/4, 
       par("usr")[1] + ltot + h/4, y0 + yh/2 + h/4, col = "white")
  x0 <- par("usr")[1] + h/2
  for (i in (1:(length(sq0))))
  {
    cha <- br0[i]
    cha <- paste(" ", cha, sep = "")
    xh <- strwidth(cha, cex = cex0)
    text(x0 + xh/2, y0, cha, cex = cex0)
    z0 <- sq0[i]
    x0 <- x0 + xh + z0/2
    if (sig0[i] >= 0)
      symbols(x0, y0, circles = z0/2, bg = "black", fg = "white",
              add = TRUE, inch = FALSE)
    else symbols(x0, y0, circles = z0/2, bg = "white", fg = "black",
                 add = TRUE, inch = FALSE)
    x0 <- x0 + z0/2
  }
  invisible()
}



scatterutil.legend.circle.grey <- function (br0, valgris, h, clegend)
{
  if (clegend <= 0) return(invisible())
  br0 <- round(br0, dig = 6)
  nborn <- length(br0)
  cex0 <- par("cex") * clegend
  x0 <- par("usr")[1] + h
  x1 <- x0
  for (i in (2:(nborn)))
  {
    x1 <- x1 + h
    cha <- br0[i]
    cha <- paste(cha, "]", sep = "")
    xh <- strwidth(cha, cex = cex0)
    if (i == (nborn)) break
    x1 <- x1 + xh + h
  }
  yh <- max(strheight(paste(br0), cex = cex0), h)
  y0 <- par("usr")[3] + yh/2 + h/2
  rect(par("usr")[1] + h/4, y0 - yh/2 - h/4, x1 - h/4, y0 + yh/2 + h/4, 
       col = "white")
  x0 <- par("usr")[1] + h
  for (i in (2:(nborn)))
  {
    symbols(x0, y0, circles = h/2, bg = gray(valgris[i - 1]), add = TRUE, 
            inch = FALSE)
    x0 <- x0 + h
    cha <- br0[i]
    if (cha < 1e-05) cha <- round(cha, dig = 3)
    cha <- paste(cha, "]", sep = "")
    xh <- strwidth(cha, cex = cex0)
    if (i == (nborn)) break
    text(x0 + xh/2, y0, cha, cex = cex0)
    x0 <- x0 + xh + h
  }
  invisible()
}



##create scalog
scalog <- function(res, np = 999, alpha = c(0.05, 0.01, 0.001), cex=2)
{
  
  # A function to compute a scalogram (Legendre and Legendre 2012, 
  # p. 864) representing the eigenvalues of an RDA with a series of 
  # spatial eigenfunctions (e.g. dbMEM) as explanatory variables.
  # The eigenfunctions must be placed in decreasing order and they
  # must be orthogonal to one another.
  # In case of RDA the R^2 is variance, in case of CCA it is inertia.
  
  # Arguments
  
  # res    An RDA or CCA result object produced by vegan::rda().
  #        The RDA or CCA must have been computed with the formula
  #        interface.
  # np     number of permutations in the RDA test
  # alpha  probability thresholds for the color coding
  
  # License: GPL-2 
  # Author: Daniel Borcard, 2017
  
  test <- anova(res, by = "terms", permutations = how(nperm = np))
  inert <- test[,2]
  variance <- inert[-length(inert)] / sum(inert)
  signi <- test$"Pr(>F)"[-length(test$"Pr(>F)")]
  n <- length(variance)
  
  if(class(res)[1] == "rda") 
    ylabel <- expression(italic(R)^{2})
  else
    ylabel <- "Inertia"
  
  plot(
    1 : n, 
    variance, 
    type = "n", 
    main = "Scalogram", 
    xlab = "Eigenfunction number", 
    ylab = ylabel
  )
  lines(1 : n, variance)
  alpha <- c(1, sort(alpha, decreasing = TRUE))
  colour <- c("white", "greenyellow", "orange", "red")
  for(i in 1 : 4)
  {
    points(
      (1 : n)[signi <= alpha[i]], 
      variance[signi <= alpha[i]], 
      pch = 22, 
      cex = cex,
      bg = colour[i]
    )
  }
  legend(
    "topright",
    fill = c("red", "orange", "greenyellow"),
    legend = c(paste("p <= ", alpha[4]), paste("p <= ", alpha[3]), 
               paste("p <= ", alpha[2]))
  )
  invisible(test)
}
#' Function to compute and test eigenvectors of spatial weighting matrices
#' 
#' This function is now deprecated. Please try the new \code{\link{listw.candidates}} and 
#' \code{\link{listw.select}} functions.
#' 
#' This function is a user-friendly way to compute and test eigenvectors for
#' various definitions of spatial weighting matrices. It combines calls to the 
#' functions \code{scores.listw} and \code{ortho.AIC}. It allows to test various
#' definitions of the spatial weighting matrix and return results of 
#' \code{scores.listw} for the best one.
#' 
#' @details This functions allows to test one binary spatial weighting matrix 
#'   (if only Y and nb are provided). It allows also to test a weighting 
#'   function based on distances (if f is provided) and a weighting function 
#'   with different values of parameters if other arguments of \code{f} are 
#'   provided.
#'   
#' @param Y A matrix with response variables (univariate or multivariate 
#'   response)
#' @param nb An object of the class \code{nb} created by functions of the 
#'   \code{spdep} package
#' @param xy Coordinates of the samples, this argument is optional and is 
#'   required only if the argument \code{f} is not null.
#' @param MEM.autocor A string indicating if all MEM must be returned or only 
#'   those corresponding to positive or negative autocorrelation
#' @param f A function of the distance that can be used as a weighting spatial 
#'   function. This argument is optional
#' @param \dots Others arguments for the function \code{f}. It defines the range
#'   of parameters which will be tested
#' @return A list with the following elements: \item{all }{A data.frame where 
#'   each row correspond to one spatial weighting matrix tested. It contains 
#'   value of parameteres tested and corrected AIC and number of orthogonal 
#'   vectors for the best model.} \item{best }{A list containing results of 
#'   scores.listw and ortho.AIC of the best spatial weighting matrix according 
#'   to corrected AIC.}
#' @author Stéphane Dray \email{stephane.dray@@univ-lyon1.fr}
#' @seealso   \code{\link{ortho.AIC}}, \code{\link{scores.listw}}
#' @references Dray S., Legendre P. and Peres-Neto P. R. (2006) Spatial 
#'   modeling: a comprehensive framework for principal coordinate analysis of 
#'   neighbor matrices (PCNM). Ecological Modelling, 196, 483--493
#' @keywords spatial
#' @examples
#' 
#' if(require(ade4) & require(spdep)){
#' 
#' data(oribatid)
#' # Hellinger transformation
#' fau <- sqrt(oribatid$fau / outer(apply(oribatid$fau, 1, sum), rep(1, ncol(oribatid$fau)), "*"))
#' # remove gradient effect
#' faudt <- resid(lm(as.matrix(fau) ~ as.matrix(oribatid$xy)))
#' 
#' # test a binary spatial weighting matrix
#' nbtri <- tri2nb(as.matrix(oribatid$xy))
#' tri.res <- test.W(faudt, nbtri)
#' 
#' maxi <- max(unlist(nbdists(nbtri, as.matrix(oribatid$xy))))
#' 
#' # test a simple spatial weighting function of the distance
#' f1 <- function(x) {1-(x)/(maxi)}
#' tri.f1 <- test.W(faudt, nbtri, f = f1, xy = as.matrix(oribatid$xy))
#' 
#' # test a spatial weighting function with various values of parameters
#' f2 <- function(x,dmax,y) {1-(x^y)/(dmax)^y}
#' tri.f2 <- test.W(faudt,nbtri, f = f2, y = 2:10, dmax = maxi, xy = as.matrix(oribatid$xy))
#' }
#' 
#' @importFrom spdep nb2listw
#' @export
#' 
"test.W" <-
  function(Y,
           nb,
           xy,
           MEM.autocor = c("all", "positive", "negative"),
           f = NULL,
           ...) {
    .Deprecated(new = "listw.select", package = "adespatial", 
                msg = "This function is now deprecated. Please try the new 'listw.select' function.")
    
    mycall <- pairlist(...)
    res <- list()
    MEM.autocor <- match.arg(MEM.autocor)
    if (!(is.null(f))) {
      nbdist <- nbdists(nb, as.matrix(xy))
      if (!(is.null(mycall))) {
        param <- expand.grid(as.list(mycall))
        m1 <- match(names(param), names(formals(f)))
        for (i in 1:nrow(param)) {
          formals(f)[m1] <- unclass(param[i,])
          res[[i]] <-
            scores.listw(nb2listw(
              nb,
              style = "B",
              glist = lapply(nbdist, f), 
              zero.policy = TRUE
            ),
            MEM.autocor = MEM.autocor)
        }
      }
      else {
        res[[1]] <-
          scores.listw(nb2listw(nb, style = "B", glist = lapply(nbdist, f)),
                       MEM.autocor = MEM.autocor)
      }
    }
    else {
      res[[1]] <-
        scores.listw(nb2listw(nb, style = "B"), MEM.autocor = MEM.autocor)
    }
    res2 <-
      lapply(res, function(x)
        ortho.AIC(
          Y = Y,
          X = x,
          ord.var = TRUE
        ))
    if (!(is.null(mycall))) {
      res3 <-
        data.frame(AICc = unlist(lapply(res2, function(x)
          min(x[[1]], na.rm = TRUE))), NbVar = unlist(lapply(res2, function(x)
            which.min(x[[1]]))))
      res3 <- cbind(param, res3)
    }
    else{
      res3 <-
        data.frame(AICc = unlist(lapply(res2, function(x)
          min(x[[1]], na.rm = TRUE))), NbVar = unlist(lapply(res2, function(x)
            which.min(x[[1]]))))
    }
    
    thebest <- which.min(res3$AICc)
    cat (paste("\n\nAICc for the null model:", res2[[thebest]]$AICc0, "\n"))
    cat ("\nBest spatial model:\n")
    print(res3[thebest,])
    
    return(list(all = res3, best = list(MEM = res[[thebest]], AIC = res2[[thebest]])))
    
  }
scalog <- function(res, np = 999, alpha = c(0.05, 0.01, 0.001), cex=2)
{

# A function to compute a scalogram (Legendre and Legendre 2012, 
# p. 864) representing the eigenvalues of an RDA with a series of 
# spatial eigenfunctions (e.g. dbMEM) as explanatory variables.
# The eigenfunctions must be placed in decreasing order and they
# must be orthogonal to one another.
# In case of RDA the R^2 is variance, in case of CCA it is inertia.

# Arguments

# res    An RDA or CCA result object produced by vegan::rda().
#        The RDA or CCA must have been computed with the formula
#        interface.
# np     number of permutations in the RDA test
# alpha  probability thresholds for the color coding

# License: GPL-2 
# Author: Daniel Borcard, 2017

test <- anova(res, by = "terms", permutations = how(nperm = np))
inert <- test[,2]
variance <- inert[-length(inert)] / sum(inert)
signi <- test$"Pr(>F)"[-length(test$"Pr(>F)")]
n <- length(variance)

if(class(res)[1] == "rda") 
  ylabel <- expression(italic(R)^{2})
else
  ylabel <- "Inertia"
   
plot(
  1 : n, 
  variance, 
  type = "n", 
  main = "Scalogram", 
  xlab = "Eigenfunction number", 
  ylab = ylabel
)
lines(1 : n, variance)
alpha <- c(1, sort(alpha, decreasing = TRUE))
colour <- c("white", "greenyellow", "orange", "red")
for(i in 1 : 4)
{
  points(
    (1 : n)[signi <= alpha[i]], 
    variance[signi <= alpha[i]], 
    pch = 22, 
    cex = cex,
    bg = colour[i]
  )
}
legend(
  "topright",
  fill = c("red", "orange", "greenyellow"),
  legend = c(paste("p <= ", alpha[4]), paste("p <= ", alpha[3]), 
             paste("p <= ", alpha[2]))
)
invisible(test)
}


```

Read the data in. Need to change FCS in coupes to fcs so it matches the other dataframes for the join.

```{r include=FALSE}

#import files and merge browsing and coupe attributes

Browsing <- read.xlsx("TPPL_FCS_data.xlsx", sheet = "Browsing_FCS")

Coupes <- read.xlsx("TPPL_FCS_data.xlsx", sheet = "Coupe attributes")

MEMdb <- left_join(Browsing, Coupes, by="fcs") # merge the pieces, coupe attributes contain the coords for the coupe centroids

```

The timberlands data does not have repeated measures like the STT data so is structurally more similar to the original lizard data so I can get straight into the MEMs process.

There are 7 coupes with a browsing survey but no shape in the TPPL shapefile that I ahve. I am querying this with TPPL but to get an idea of how the MEMs look I'll exclude those 7 for now.

```{r}
MEMdb <- MEMdb[!is.na(MEMdb$LinkKey),]
```

There are also some fcs values where 0 trees were evaluated and therefore have missing values for the damage levels. Need to get rid of these as well.

```{r}
MEMdb <- MEMdb[!is.na(MEMdb$Dmg_light),]
```

## Plot the location of the populations

```{r echo=TRUE}
require(sf)
require(mapview)
coor <- st_as_sf(x = MEMdb, # Transforming coordinate points to spatial data
                        coords = c("xcoord", "ycoord"),  # The name of the variables where your coords are
                         crs = "+proj=longlat +datum=WGS84") # The reference system of coordinates

mapview(coor)
```

## Transform the coordinates so that we can analyse them

Need to transform the coords in to metres not degrees but the SoDa package used by Mara was archived in 2022. I should be able to fix this by transforming the data I have into a different CRS that uses metres instead of degrees

```{r}
# Create an sf object from MEMdb
sf_data <- st_as_sf(MEMdb, coords = c("xcoord", "ycoord"), crs = "+proj=longlat +datum=WGS84")

# Transform the coordinates to a different projection (in meters)
sf_data_meters <- st_transform(sf_data, crs = 3857)

# Convert the sf object back to a data frame or tibble
MEMdb <- as.data.frame(sf_data_meters)

#change the coordinates to the conversions
MEMdb$xcoord <- st_coordinates(sf_data_meters)[,1]
MEMdb$ycoord <- st_coordinates(sf_data_meters)[,2]
```

Convert this info into a spatial points dataframe

```{r include=FALSE}
dataDBMEMmulti <- MEMdb
coordinates(dataDBMEMmulti) <- 18:19
```

## Rename variables for the downstream analyses

```{r}
DBMEMmulti <- data.frame(Dmg_L = dataDBMEMmulti@data$Dmg_light, # % w. light damage
                         Dmg_M = dataDBMEMmulti@data$Dmg_mid, # % w. medium damage
                         Dmg_H = dataDBMEMmulti@data$Dmg_heavy, # % w. heavy damage
                         fcs = dataDBMEMmulti@data$fcs, # spatial identifier
                         Lat = MEMdb$ycoord,
                         Lon = MEMdb$xcoord)
```

```{r}
BrNdb  <- DBMEMmulti[,c("Dmg_L")] # select the column with response variable 
ZBrNdb <- scale(BrNdb) # Scale the response variable
xydb <- DBMEMmulti[,c("Lon", "Lat")] # These are the columns with the x and y coordinates
```

##-------------------------MULTIVARIATE SPATIAL ANALYSES---------------------------------##

## First we test for a linear trend in the data for browse damage and seedling height

```{r}
#Test for spatial trend in the data [see Borcard et al. p.314; Legendre & Legendre p 868]
BrNdbxy.rda <- rda(xydb, ZBrNdb)
anova(BrNdbxy.rda)
```

```{r}
# There is evidence for a linear trend in the data so we proceed with the detrended data 

BrN.det.db <- resid(lm(as.matrix(ZBrNdb)~.,data=xydb)) # Here we detrend the data 
```

## Correlogram on detrended phenotypic data (greenness and blackness)

```{r fig.cap="Fig. S1.1. Correlogram for the IT lineage" }

BrN.db.det.D1 <- dist(ZBrNdb) # We can investigate the trend by creating Euclidian distance matrix of the phenotypes

BrN.correlogrmdb <- mantel.correlog(BrN.db.det.D1,
                                   XY=as.data.frame(xydb),
                                   nperm= 10) # Perform correlogram 

plot(BrN.correlogrmdb) #Plot the correlogram: Correlogram shows the results of Mantel tests(spatial autocorrelation tests). The x axis is the distance in meters, Y axis is Mantel correlation. Black filled squares represent significant correlation (Positive values=positive correlation, negative values = negative correlation).

# Positive spatial correlation means that the data is clustered spatially (neighbouring populations are similar to each other). 

# Significant negative spatial correlations indicate that data is more dispersed than expected.
```

# ANALYSES USING dbMEM

We follow these steps (described in Borcard et al. 2018, Ch 7):

1.  Construct a matrix of Euclidian geographic distances
2.  Truncate this distances to retain only distances among closest neighbours
3.  Compute a principal component analyses of the truncated distances
4.  Obtain the positive spatial autocorrelation by eigenvectors (MEMs)
5.  Use the MEMs as a spatial explanatory variables in a Redundancy Analysis

## Construct a matrix of Euclidian geographic distances

```{r}
dbmem.tmp <- dbmem(xydb, silent= FALSE) # Using the coordinates to find MEMs
xy.dbmem <- as.data.frame(dbmem.tmp)

# Truncation distance. This is the maximum distance of a spanning tree.

(thr <- give.thresh(dist(xydb)))

attributes(dbmem.tmp)$values
length(attributes(dbmem.tmp)$values) # Number of positive eigenvectors
```

## Run an RDA on the detrended phenotype data

```{r, include=FALSE}
(dbmem.rda.BrN <- rda(BrN.det.db~ .,xy.dbmem)) # redundancy analyses with detrended BrN and MEMs 
# summary(dbmem.rda.GB)
anova(dbmem.rda.BrN)
(dbaxes.test.BrN <- anova(dbmem.rda.BrN, by= "axis"))
```

## Forward selection of MEMs to get only significant and positive MEMs

```{r}

# Note that forward selection of MEMs can vary slightly between runs. 

(dbmem.rda.r.BrN <- RsquareAdj(dbmem.rda.BrN)$adj.r.squared) # Here we create a variable which contains R2 of our model
(dbmem.fwd.BrN <- forward.sel(BrN.det.db, as.matrix(xy.dbmem), 
                        adjR2thresh = dbmem.rda.r.BrN)) # Then we use that variable to forward select MEMs

(significant.dbMEM.BrN <- nrow(dbmem.fwd.BrN)) # Then we create a variable with the significant MEMs
(significant.dbMEM.BrN<- sort(dbmem.fwd.BrN[,2]))# sort eigenvectors as the go from broader spatial structure to finer
```
Results show there are no significant MEMs for heavy or mid damage (only light damage has sig MEMs) - ie the data has no apparent spatial structure. Each coupe is an individual entity with no relation to those around it? Temporal variables are more important? - could account for some of this using a random effect for year established in any models?

## Create a new object with the significant eigenvalues

```{r}
dbmem.red.BrN <- xy.dbmem[,c(significant.dbMEM.BrN)]
dbmem.red.BrN
```

## New dbMEm ananlyses with forward-selected, significiant, MEMs

```{r}
#added this line to convert to a dataframe so that the rest of the analysis in this chunk runs correctly
dbmem.red.BrN <- as.data.frame(dbmem.red.BrN)

(dbmem.rda2.BrN <- rda(BrN.det.db ~ ., data = dbmem.red.BrN))  # Run analyses with significant MEMS only
(dbmem.rda2.r.BrN <- RsquareAdj(dbmem.rda2.BrN)$adj.r.squared)
#summary(dbmem.rda2.GB)
anova(dbmem.rda2.BrN)
(dbaxes.test.BrN <- anova(dbmem.rda2.BrN, by= "axis")) 

# The results of the model showed that only one axis, RDA1, is significant. This axes explains ca 32.5% of the variance (from the R2 statement)

```

## Triplot for the dbMEM RDA

```{r fig.cap="Fig. S1.2. Triplot of the dbMEM RDA on greenness and blackness.Negative values of RDA1 indicate black and green individuals and positive values brown and white individuals."}

## Plot the scores. Variance explained is obtained by multiplying accumulated constrained eigenvalues variance for each axis with the adjusted R2. To know the whole variance explained we use the accumulated value.

dbmem.rda2.BrN$CCA$v
dbmem.rda2.BrN$CCA$eig


par(mar=c(4,4,2,2))
plot(dbmem.rda2.BrN, xlab="RDA1", ylab="RDA2",
     display=c("cn", "lc", "sp"), type="n", xlim=c(-1,1), ylim=c(-1,2))
sites.sc <- scores(dbmem.rda2.BrN, choices=1:2, scaling=2, display="lc")
points(sites.sc, pch=1, cex=0.5)
va.sc <- scores(dbmem.rda2.BrN, choices=1:2, scaling=2, display="sp")
text(va.sc, row.names(va.sc), cex=0.5)
text(dbmem.rda2.BrN, scaling=3, display="bp", cex=0.5, font=2, pos=3)
unit.sc <- scores(dbmem.rda2.BrN, choices=1:2, scaling=2, display="cn")
points(unit.sc, pch=23)
```

# Plot fitted scores on the map

```{r, fig.cap = "Fig. S1.3. dbMEM analysis of the detrended greenness and blackness data with the 4 significant dbMEM variable. Maps pf the fitted scores of the first (statistically) significant axis. The color and size of the circles indicate the sign and magnitude of the fitted scores - from fig S1.2 we can see that white indicates locations with highly green and black individuals." }

dbnb.ax.BrN <- length(which(dbaxes.test.BrN[ ,ncol(dbaxes.test.BrN)] <= 0.05))

#adding some code to set limits for the x and y axes that will hopefully zoom in on the overlapping bubbles to give more info. can use these limits later with the MEMs graphs.

xlim <- c(16090000, 16580000)
ylim <- c(-5420000, -4900000)
          
dbmem.rda2.axes.BrN <- 
  scores(dbmem.rda2.BrN,
         choices=c(1:dbnb.ax.BrN),
         display ="lc",
         scaling= 1)
par(mfrow = c(1,1))
for(i in 1:dbnb.ax.BrN){
 sr.value(xydb,dbmem.rda2.axes.BrN[,i],
           sub = paste("RDA",i),
           csub=2,
          xlim = xlim , ylim = ylim)} #Maps of the fitted site scores of the canonical axes that are significant at the alpha=0.05 treshold

DBMEMmulti$RDA1 <- dbmem.rda2.axes.BrN[,1]

# The plot represents the spatially structured variation in RDA1. Here negative values represent green and black and vice versa. Size is proportional to the value of RDA1. 

# RDA2 is not significant so not used further, but it could be added too
# DBMEMmulti$RDA2 <- dbmem.rda2.axes.GB[,2]

# write.csv2(DBMEMmulti, file="C:/Users/Tobias/Dropbox/Tobias Documents/Lund/Students/Mara/Mara_PhD_TU/LandscapePhenotype/Data/RDA_ITA.csv") # If you wish to save new Dataframe with RDA

```

# Scalogram of the variance explained by the dbMEM eigenfunction

```{r, fig.cap = "Scalogram showing the unadjusted R2 of the detrended greenness and blackness data explained by the dbMEMs. Colour coding from permutations. Note that two large scale MEMs are borderline significant and not selected in the analyses above"}

# This scalogram shows the explained variance (note: unadjusted R2) of the detrended data explained by the dbMEM eigenfunctions, with color coded permutation test results.

scalog(dbmem.rda.BrN)
```

# Plot significant dbMEMs

```{r}
par(mfrow =c(1,2))
for(i in 1 : ncol(dbmem.red.BrN))
{sr.value(xydb,
          dbmem.red.BrN[,i],
          sub=paste("MEM",significant.dbMEM.BrN[i]),
          csub=2,
          xlim = xlim, ylim = ylim)} # Plot significant eigenvectors
```

# Add the significant MEMs to the data frame

```{r}
DBMEMmulti$MEM3 <- dbmem.red.BrN[,1]
DBMEMmulti$MEM6 <- dbmem.red.BrN[,1]
DBMEMmulti$MEM9 <- dbmem.red.BrN[,1]
DBMEMmulti$MEM11 <- dbmem.red.BrN[,1]
DBMEMmulti$MEM14 <- dbmem.red.BrN[,1]
DBMEMmulti$MEM62 <- dbmem.red.BrN[,1]
DBMEMmulti$MEM195 <- dbmem.red.BrN[,1]
DBMEMmulti$MEM284 <- dbmem.red.BrN[,1]
DBMEMmulti$MEM309 <- dbmem.red.BrN[,1]
DBMEMmulti$MEM370 <- dbmem.red.BrN[,1]
DBMEMmulti$MEM463 <- dbmem.red.BrN[,1]
```


Following code applies to the environmental variables IDed for lizard work - I'm going to PCA some of my predictors and then see what aligns best with my significant MEMs.

## The next step is to assess if this spatial variation is related to our predictors; PC1 and PC2

### To do this we regress the fitted site scores of the significant canonical axis (RDA1) on the environmental data by means of linear models (lm).

```{r}

dbrda2.env.GB.1 <- lm(RDA1 ~ PC1 + PC2, data=DBMEMmulti) # Here we test the effect of our predictors on the significant canonical axis (RD1)
summary(dbrda2.env.GB.1)
shapiro.test(resid(dbrda2.env.GB.1)) # check that residuals are reasonably well behaved

# Since we only have two predictors, there is not much need for model selection, but it can be done

#dbrda2.env.GB.2 <- lm(RDA1 ~ PC1, data=DBMEMmulti) # Here we test the effect of our predictors on the significant canonical axis (RD1)
#summary(dbrda2.env.GB.2)
#shapiro.test(resid(dbrda2.env.GB.2))

#dbrda2.env.GB.3 <- lm(RDA1 ~ PC2, data=DBMEMmulti) # Here we test the effect of our predictors on the significant canonical axis (RD1)
#summary(dbrda2.env.GB.3)
#shapiro.test(resid(dbrda2.env.GB.3))

#MuMIn::model.sel(dbrda2.env.GB.1,dbrda2.env.GB.2,dbrda2.env.GB.3)

```

## Next we combine dbMEM and variance partitioning to understand how the explained variance is shared between our main predictors (climate PC1 and PC2), linear trend (x,y coords), and spatial structure (dbMEM)

```{r}

testpred <- as.data.frame(DBMEMmulti[,c(8,9)]) # select PC1 and PC2
PhenEnvdb <- rda(PhendbGB~ .,testpred) # Run rda with climate and phenotype in no detrended data
#summary(PhenEnvdb)
(phen.env.R2adb.GB <- RsquareAdj(PhenEnvdb)$adj.r.squared) # Select significant eigenvectors R2
dbenv.forward.GB <- forward.sel(PhendbGB, testpred,
                           adjR2thresh = phen.env.R2adb.GB,
                           nperm=9999)

env.signdb.GB <- sort(dbenv.forward.GB$order) # Order eigenvectors
env.reddb.GB <- testpred[,c(env.signdb.GB)]
colnames(env.reddb.GB)

```

## Now we test the unique fractions of climate, linear trend, and spatial structure using conditional rda()

```{r}

mvarpart.GB <- varpart(PhendbGB,env.reddb.GB, xydb,dbmem.red.GB) # These are our total variation and three components

par(mfrow=c(1,1))
# showvarparts(4,bg=c("red","blue","yellow"))
plot(mvarpart.GB,digits=2,bg = c("red","yellow","dark green"), Xnames = c("Climate" ,"Linear trend" ,"Spatial")) # Variogram analyses

#Test significance of each of the terms
a.GB<- anova(rda(PhendbGB,env.reddb.GB, cbind(xydb,dbmem.red.GB)))  #These are called partial rda. The first term is explanatory variable (greenness and blackness in our case), 2nd env.reddb.GB is the response variable, and 3rd cbind(...) are the covariables. This allow us to test for the effect of one while holding constant the effect of the other components.

summary(rda(PhendbGB,env.reddb.GB, cbind(xydb,dbmem.red.GB)))
a.GB

b.GB <-anova(rda(PhendbGB,xydb, cbind(env.reddb.GB,dbmem.red.GB)))
b.GB

c.GB <-anova(rda(PhendbGB,dbmem.red.GB, cbind(env.reddb.GB,xydb)))
c.GB


```

##-------------------------UNIVARIATE SPATIAL ANALYSES---------------------------------##

## The code below performs the univarate analyses for greenness and blackness using linear random effect regression models that eliminates residual spatial dependence using Moran eigenvectors. The analyses are performed using the package spmoran (Murakami 2020)

## The first analyses assumes that coefficients do not vary across the landscape

## The second analyses allows spatially varying coefficients (SVCs)

```{r include=FALSE}
library(pacman)

p_load(ade4, adespatial, car, corrplot, corrgram, data.table, FactoMineR, geosphere,  ggpubr, ggplot2, grid, gridExtra, here, Hmisc, tibble,
       LandGenCourse, lattice, leafem, mapview, MuMIn, nlme, openxlsx, proxy, readxl, sf, sjPlot, sp, spdep, spmoran, tibble, vegan)
#packages in alphabetic order
```

## Correlations Matrix

### This simply visualizes the data for greenness, blackness and their relationship to PC1 and PC2

```{r, echo=FALSE}

# It can be useful to look at these correlations

Correlations_data <- data.frame(BrN = dataDBMEMmulti@data$Browse_num, 
                         H = dataDBMEMmulti@data$Height,
                         Lat = MEMdb$ycoord, 
                         Lon = MEMdb$xcoord) 


rcorr(as.matrix(Correlations_data))#first matrix shows correlations and second statistical significance 

# Correlation plots

correlations2 <- Correlations_data[complete.cases(Correlations_data),]

a<-ggplot(correlations2, aes(x = BrN, y = H), 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Mean browse", ylab = "Mean Height") +geom_point() #Correlation coefficient R= 0.8
a

b<-ggplot(correlations2, aes(x = Lon, y = BrN), 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Lon", ylab = "Mean browse") +geom_point() #Correlation coefficientR= -0.71
b

c<-ggplot(correlations2, aes(x = Lon, y = H), 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Lon", ylab = "Mean Height") +geom_point() #Correlation coefficient R= -0.48
c

d<-ggplot(correlations2, aes(x = Lat, y = BrN), 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Lat", ylab = "Mean browse") + geom_point() #Correlation coefficient R=-0.49
d

e<-ggplot(correlations2, aes(x = Lat, y = H), 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Lat", ylab = "Mean Height") + geom_point() #Correlation coefficient R=-0.4
e
```

```{r}
# Arrange and save
g<-  grid.arrange(a+theme(axis.text=element_text(size=8),axis.title=element_text(size=8,face="bold")),ncol = 1,nrow=1)
graphs <- grid.arrange(b+theme(axis.text=element_text(size=12),
        axis.title=element_text(size=8,face="bold")),c+theme(axis.text=element_text(size=8),
        axis.title=element_text(size=8,face="bold")),ncol = 2,nrow=1)
graphs1<-grid.arrange(d+theme(axis.text=element_text(size=8),
        axis.title=element_text(size=8,face="bold")),e+theme(axis.text=element_text(size=8),
          axis.title=element_text(size=8,face="bold")),ncol = 2,nrow=1)

#ggsave("graphs.png", width = 30, height = 40, units = "cm", dpi = 600) #saves the plot
```

# Distance-based Moran eigenvector maps analysis using package spmoran (Murakami 2020).

### MRM Most of the code below has been obtained from <https://arxiv.org/pdf/1703.04467.pdf>. More detailed information about the package <https://github.com/dmuraka/spmoran>

## First we test for a linear trend in the data for greenness (GM) and blackness (B)

```{r, echo=TRUE}
#Test for spatial trend in the data [see Borcard et al. p.314; Legendre & Legendre p 868]
# Pick out greenness and blackness
Browse  <- scale(DBMEMmulti$BrN) # standardize mean browsing
Height  <- scale(DBMEMmulti$H) # standardize mean height

dbBrowse.lm<- lm(Browse~.,data=xydb) # We test here linear trend with linear models
anova(dbBrowse.lm)
(linear_trend <- RsquareAdj(dbBrowse.lm)$adj.r.squared) # Here we create a variable which contains R2 of our model

# There is evidence for a linear trend in the data so we proceed with the detrended data 

B.detrend<- resid(lm(Browse~.,data=xydb)) # Here we detrend the data 

Phen.db.D1 <- dist(as.matrix(Browse)) # We can investigate the trend by creating Euclidian distance matrix of detrended green

Phen.correlogrmdb <- mantel.correlog(Phen.db.D1,
                                   XY=as.data.frame(xydb), nperm= 999) # Perform correlogram on detrended data

plot(Phen.correlogrmdb) # Plot the correlogram
```

```{r}
dbHeight.lm<- lm(Height~.,data=xydb) #We test here linear trend with linear models
anova(dbHeight.lm)
(linear_trend <- RsquareAdj(dbHeight.lm)$adj.r.squared) # Here we create a variable which contains R2 of our model

# There is evidence for a linear trend in the data so we proceed with the detrended data 

H.detrend<- resid(lm(Height~.,data=xydb)) # Here we detrend the data 

Phen.db.D1 <- dist(as.matrix(H.detrend)) # We can investigate the trend by creating Euclidian distance matrix of detrended green

Phen.correlogrmdb <- mantel.correlog(Phen.db.D1,
                                   XY=as.data.frame(xydb),nperm= 999) # Perform correlogram 

plot(Phen.correlogrmdb) # Plot the correlogram

```

# 1. Analysis of Dorsal Greenness

## A. Random Effects (RE_ESF) Model

```{r}

# Random effects regression model with PC1 and PC2 as explanatory variables and controlling for spatial structure using dbMEMs

meig <- meigen(coords = xydb) # Spanning tree

Browserandom <- spmoran::resf( y = B.detrend, x = xydb,                            
                           meig = meig , method = "reml" )
Browserandom$b 
Browserandom

## Output 
# 1) Estimates of Lon and Lat and their statistical significance
# 2) random_SE and Moran.I refers to the spatial terms
# **random_SE**: when squared, this tells us how much variance was captured by the MEM eigenvectors. (bigger values more spatial autocorrelation)
# **Moran.I/max(Moran.I)**: this give an indication of the spatial scale of the observed pattern. A value close to 1 would indicate large-scale spatial structure, and clsoe to 0 small-scale spatial structure

# 3) Stats of the whole model: resid_SE, adj R2, AIC and BC

## to test significance of the spatial term we can compare AIC or BIC values of a linear model with no MEMS

Browse2  <- lm( Browse~ Lon+Lat,DBMEMmulti)
summary(Browse2) 
AIC(Browse2)
BIC(Browse2)

```

## B. Spatially and non-spatially varying coefficients model

### So far, we have fitted the same model for all sites. Spatial filtering with MEM makes it possible to relax this assumption, and the 'spmoran' tutorial calls this a 'Spatially Varying Coefficients' model (SVC). The main advantage is that we can visualize how the slope parameter estimates, and their p-values, vary across the study area separately for PC1 and PC2. We evaluate if inclusion of a SVC is justified on the basis of AIC.

```{r}
#This function estimates the random effects eigenvector spatial filtering model with varying coefficients
Grv_res <- resf_vc(y= B.detrend, 
                            x = DBMEMmulti[,c("Lon","Lat")],
                            meig = meig,x_sel=TRUE, penalty="aic") # with x_sel=TRUE we allow both terms to vary but only do so if it improves the model fit (here we use AIC, but BIC is also an option)

summary( Grv_res$b_vc ) # estimates of SVCs
summary( Grv_res$p_vc ) # Matrix of estimated p-values for the SVCs

Grv_res$p_vc
Grv_res 
# a) a summary of how many places are significant for PC1 and PC2 and their significance level
# b) Moran coefficient for each climatic axis. This shows spatial structure of phenotype with respct to PC1 and PC2 
# c) Statistics for the whole model

```

### Plots of coefficients

```{r}
BrowseRandom <- data.frame(DBMEMmulti, b=Grv_res$b_vc, p=Grv_res$p_vc)

# These plots produce maps of the different coefficients, coloured according to significant or not (at p < 0.05) and with the size proportional to the value each site takes on
par(mfrow=c(2,4))
require(ggplot2)
BrowseP <-ggplot(as.data.frame(BrowseRandom), aes(x, y, size=BrN)) + # raw greenness
  geom_point(color="darkgreen") + coord_fixed()+
  theme(axis.line=element_blank(),
      axis.text.x=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks=element_blank(),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      legend.position="none",
      panel.background=element_blank(),
      panel.border=element_blank(),
      panel.grid.major=element_blank(),
      panel.grid.minor=element_blank(),
      plot.background=element_blank())

PC1P <-ggplot(as.data.frame(GreenRandom), aes(x, y, size=PC1)) + # climatic PC1
  geom_point(color="Red") + coord_fixed()+
  theme(axis.line=element_blank(),
      axis.text.x=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks=element_blank(),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      legend.position="none",
      panel.background=element_blank(),
      panel.border=element_blank(),
      panel.grid.major=element_blank(),
      panel.grid.minor=element_blank(),
      plot.background=element_blank())
PC2P <-ggplot(as.data.frame(GreenRandom), aes(x, y, size=PC2)) + # climatic PC2
  geom_point(color="Yellow") + coord_fixed()+
  theme(axis.line=element_blank(),
      axis.text.x=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks=element_blank(),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      legend.position="none",
      panel.background=element_blank(),
      panel.border=element_blank(),
      panel.grid.major=element_blank(),
      panel.grid.minor=element_blank(),
      plot.background=element_blank())
PC1_mod <- ggplot(as.data.frame(GreenRandom), aes(x, y, col=p.PC1 < 0.05, size=b.PC1)) + # coefficients for PC1 and their significance
  geom_point() + coord_fixed()+
  theme(axis.line=element_blank(),
      axis.text.x=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks=element_blank(),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      legend.position="none",
      panel.background=element_blank(),
      panel.border=element_blank(),
      panel.grid.major=element_blank(),
      panel.grid.minor=element_blank(),
      plot.background=element_blank())

PC2_mod <-ggplot(as.data.frame(GreenRandom), aes(x, y, col=p.PC2 < 0.05, size=b.PC2)) + # coefficients for PC2 and their significance
  geom_point() + coord_fixed() +
  theme(axis.line=element_blank(),
      axis.text.x=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks=element_blank(),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      legend.position="none",
      panel.background=element_blank(),
      panel.border=element_blank(),
      panel.grid.major=element_blank(),
      panel.grid.minor=element_blank(),
      plot.background=element_blank())

ggarrange(GreenP, PC1P, PC2P,PC1_mod,PC2_mod , 
          labels = c("A", "B", "C","D","E","F"),
          ncol = 3, nrow = 2)
ggarrange(GreenP, PC1_mod,PC2_mod , 
          labels = c("A", "B", "C"),
          ncol = 3, nrow = 1)

# The following plots are perhaps easier to understand. The estimate of the coefficients is represented by colours. The first plot produces all coefficients and the second only those that are statistically significant p < 0.05
plot_s(Grv_res, xnum = 2) # xnum select PC2
plot_s(Grv_res, xnum = 2, pmax =0.05) # xnum select PC2

```

# 2. Analyses of Ventral blackness

## A. Random Effects (RE_ESF) Model

```{r}

# This is the same as above but on blackness

# Random effects regression model with PC1 and PC2 as explanatory variables and controlling for spatial structure using dbMEMs

meig <- meigen( coords = xydb ) # Spanning tree

Blackrandom <- spmoran::resf( y=B.detrend, x=DBMEMmulti[,c("PC1","PC2")],                            
                           meig = meig , method = "reml" )
Blackrandom$b 
Blackrandom

## Output 
# 1) Estimates of PC1 and PC2 and their statistical significance
# 2) random_SE and Moran.I refers to the spatial terms
# **random_SE**: when squared, this tells us how much variance was captured by the MEM eigenvectors. (bigger values more spatial autocorrelation)
# **Moran.I/max(Moran.I)**: this give an indication of the spatial scale of the observed pattern. A value close to 1 would indicate large-scale spatial structure, and clsoe to 0 small-scale spatial structure

# 3) Stats of the whole model: resid_SE, adj R2, AIC and BC

## to test significance of the spatial term we can compare AIC or BIC values of a linear model with no MEMS

Black2  <- lm(B.detrend~ PC1+PC2,DBMEMmulti)
summary(Black2) 
AIC(Black2)
BIC(Black2)

```

## B. Spatially and non-spatially varying coefficients model

###So far, we have fitted the same model for all sites. Geographically weighted regression (GWR) would allow relaxing this. Spatial filtering with MEM can be used to accomplish the same goal, and the 'spmoran' tutorial calls this a 'Spatially Varying Coefficients' model (SVC). The main advantage is that we can visualize how the slope parameter estimates, and their p-values, vary across the study area sepparately for PC1 and PC2. We evaluate if inclusion of a SVC is justified on the basis of AIC.

```{r}
#This function estimates the random effects eigenvector spatial filtering model with varying coefficients
Brv_res <- resf_vc(y= B.detrend, 
                            x = DBMEMmulti[,c("PC1","PC2")],
                            meig = meig,x_sel=TRUE, penalty="aic") # with x_sel=TRUE we allow both terms to vary but only do so if it improves the model fit (here we use AIC, but BIC is also an option)

summary(Brv_res$b_vc ) # estimates of SVCs
summary(Brv_res$p_vc ) # Matrix of estimated p-values for the SVCs

Brv_res$p_vc
Brv_res 
# a) a summary of how many places are significant for PC1 and PC2 and their significance level
# b) Moran coefficient for each climatic axis. This shows spatial structure of phenotype with respct to PC1 and PC2 
# c) Statistics for the whole model

```

### Plots of coefficients

```{r}
BlackRandom <- data.frame(DBMEMmulti, b=Brv_res$b_vc, p=Brv_res$p_vc)

# These plots produce maps of the different coefficients, coloured according to significant or not (at p < 0.05) and with the size proportional to the value each site takes on
par(mfrow=c(2,4))
require(ggplot2)
BlackP <-ggplot(as.data.frame(BlackRandom), aes(x, y, size=B)) + # raw blackness
  geom_point(color="darkgreen") + coord_fixed()+
  theme(axis.line=element_blank(),
      axis.text.x=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks=element_blank(),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      legend.position="none",
      panel.background=element_blank(),
      panel.border=element_blank(),
      panel.grid.major=element_blank(),
      panel.grid.minor=element_blank(),
      plot.background=element_blank())

PC1P <-ggplot(as.data.frame(BlackRandom), aes(x, y, size=PC1)) + # climatic PC1
  geom_point(color="Red") + coord_fixed()+
  theme(axis.line=element_blank(),
      axis.text.x=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks=element_blank(),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      legend.position="none",
      panel.background=element_blank(),
      panel.border=element_blank(),
      panel.grid.major=element_blank(),
      panel.grid.minor=element_blank(),
      plot.background=element_blank())
PC2P <-ggplot(as.data.frame(BlackRandom), aes(x, y, size=PC2)) + # climatic PC2
  geom_point(color="Yellow") + coord_fixed()+
  theme(axis.line=element_blank(),
      axis.text.x=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks=element_blank(),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      legend.position="none",
      panel.background=element_blank(),
      panel.border=element_blank(),
      panel.grid.major=element_blank(),
      panel.grid.minor=element_blank(),
      plot.background=element_blank())
PC1_mod <- ggplot(as.data.frame(BlackRandom), aes(x, y, col=p.PC1 < 0.05, size=b.PC1)) + # coefficients for PC1 and their significance
  geom_point() + coord_fixed()+
  theme(axis.line=element_blank(),
      axis.text.x=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks=element_blank(),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      legend.position="none",
      panel.background=element_blank(),
      panel.border=element_blank(),
      panel.grid.major=element_blank(),
      panel.grid.minor=element_blank(),
      plot.background=element_blank())

PC2_mod <-ggplot(as.data.frame(BlackRandom), aes(x, y, col=p.PC2 < 0.05, size=b.PC2)) + # coefficients for PC2 and their significance
  geom_point() + coord_fixed() +
  theme(axis.line=element_blank(),
      axis.text.x=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks=element_blank(),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      legend.position="none",
      panel.background=element_blank(),
      panel.border=element_blank(),
      panel.grid.major=element_blank(),
      panel.grid.minor=element_blank(),
      plot.background=element_blank())

ggarrange(BlackP, PC1P, PC2P,PC1_mod,PC2_mod , 
          labels = c("A", "B", "C","D","E","F"),
          ncol = 3, nrow = 2)
ggarrange(BlackP, PC1_mod,PC2_mod , 
          labels = c("A", "B", "C"),
          ncol = 3, nrow = 1)

# The following plots are perhaps easier to understand. The estimate of the coefficients is represented by colours. The first plot produces all coefficients and the second only those that are statistically significant p < 0.05
plot_s(Brv_res, xnum = 1) # xnum select PC1
plot_s(Brv_res, xnum = 1, pmax =0.05) # xnum select PC1

```
